#!/usr/bin/env python
"""
Test complet du syst√®me d'√©valuation IA des vid√©os d'entretien
Ce script teste l'ensemble de la pipeline d'√©valuation IA.
"""

import os
import sys
import django
from django.conf import settings

# Configuration Django
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'prototype.settings')
django.setup()

from interviews.models import AiEvaluation, InterviewAnswer, InterviewQuestion, InterviewCampaign, JobOffer
from interviews.services.ai_video_evaluation_service import AIVideoEvaluationService
from interviews.serializers import AiEvaluationSerializer, AiEvaluationCreateSerializer
from users.models import CustomUser
from django.test import RequestFactory
from interviews.views import AiEvaluationViewSet
from rest_framework.test import APIRequestFactory
import json

def test_ai_evaluation_system():
    """Test complet du syst√®me d'√©valuation IA"""
    
    print("üöÄ D√âBUT DU TEST COMPLET D'√âVALUATION IA")
    print("=" * 60)
    
    # 1. Test du mod√®le AiEvaluation
    print("\n1Ô∏è‚É£ Test du mod√®le AiEvaluation...")
    try:
        # V√©rifier que le mod√®le existe et est accessible
        ai_evaluations = AiEvaluation.objects.all()
        print(f"‚úÖ Mod√®le AiEvaluation accessible - {ai_evaluations.count()} √©valuations existantes")
        
        # Test des m√©thodes du mod√®le
        if ai_evaluations.exists():
            evaluation = ai_evaluations.first()
            print(f"   - Grade communication: {evaluation.get_score_grade(evaluation.communication_score)}")
            print(f"   - Grade global: {evaluation.get_overall_grade()}")
            print(f"   - Statut: {evaluation.get_status_display()}")
        
    except Exception as e:
        print(f"‚ùå Erreur mod√®le AiEvaluation: {e}")
        return False
    
    # 2. Test du service d'√©valuation IA
    print("\n2Ô∏è‚É£ Test du service AIVideoEvaluationService...")
    try:
        ai_service = AIVideoEvaluationService()
        print("‚úÖ Service d'√©valuation IA initialis√©")
        
        # V√©rifier les m√©thodes disponibles
        methods = [method for method in dir(ai_service) if not method.startswith('_')]
        print(f"   - M√©thodes disponibles: {', '.join(methods)}")
        
    except Exception as e:
        print(f"‚ùå Erreur service IA: {e}")
        return False
    
    # 3. Test des serializers
    print("\n3Ô∏è‚É£ Test des serializers...")
    try:
        # Test AiEvaluationSerializer
        if ai_evaluations.exists():
            evaluation = ai_evaluations.first()
            serializer = AiEvaluationSerializer(evaluation)
            serialized_data = serializer.data
            print("‚úÖ AiEvaluationSerializer fonctionne")
            print(f"   - Champs s√©rialis√©s: {len(serialized_data)} champs")
            
            # Afficher quelques champs format√©s
            if 'status_display' in serialized_data:
                print(f"   - Statut format√©: {serialized_data['status_display']}")
            if 'processing_time_display' in serialized_data:
                print(f"   - Temps de traitement: {serialized_data['processing_time_display']}")
        
        # Test AiEvaluationCreateSerializer
        create_serializer = AiEvaluationCreateSerializer(data={
            'interview_answer_id': 1,
            'force_reevaluation': False
        })
        print(f"‚úÖ AiEvaluationCreateSerializer - Validation: {create_serializer.is_valid()}")
        
    except Exception as e:
        print(f"‚ùå Erreur serializers: {e}")
        return False
    
    # 4. Test des vues API
    print("\n4Ô∏è‚É£ Test des vues API...")
    try:
        factory = APIRequestFactory()
        viewset = AiEvaluationViewSet()
        
        # Test de la m√©thode get_queryset
        request = factory.get('/api/interviews/ai-evaluations/')
        
        # Cr√©er un utilisateur de test
        try:
            admin_user = CustomUser.objects.filter(is_superuser=True).first()
            if not admin_user:
                admin_user = CustomUser.objects.filter(role='ADMIN').first()
            
            if admin_user:
                request.user = admin_user
                viewset.request = request
                queryset = viewset.get_queryset()
                print(f"‚úÖ ViewSet get_queryset fonctionne - {queryset.count()} √©valuations")
            else:
                print("‚ö†Ô∏è Aucun utilisateur admin trouv√© pour tester les vues")
                
        except Exception as e:
            print(f"‚ö†Ô∏è Test des vues limit√©: {e}")
        
    except Exception as e:
        print(f"‚ùå Erreur vues API: {e}")
        return False
    
    # 5. Test de la structure des donn√©es
    print("\n5Ô∏è‚É£ Test de la structure des donn√©es...")
    try:
        # V√©rifier les relations entre mod√®les
        interview_answers = InterviewAnswer.objects.filter(
            cloudinary_secure_url__isnull=False
        ).select_related('question__campaign__job_offer', 'candidate')
        
        print(f"‚úÖ R√©ponses avec vid√©os trouv√©es: {interview_answers.count()}")
        
        if interview_answers.exists():
            answer = interview_answers.first()
            print(f"   - Candidat: {answer.candidate.username}")
            print(f"   - Question: {answer.question.text[:50]}...")
            print(f"   - Campagne: {answer.question.campaign.title}")
            print(f"   - URL vid√©o: {'Oui' if answer.cloudinary_secure_url else 'Non'}")
            
            # V√©rifier si une √©valuation IA existe pour cette r√©ponse
            ai_eval = AiEvaluation.objects.filter(interview_answer=answer).first()
            if ai_eval:
                print(f"   - √âvaluation IA: {ai_eval.status} (Score: {ai_eval.overall_ai_score})")
            else:
                print("   - Aucune √©valuation IA pour cette r√©ponse")
        
    except Exception as e:
        print(f"‚ùå Erreur structure donn√©es: {e}")
        return False
    
    # 6. Test des endpoints disponibles
    print("\n6Ô∏è‚É£ Test des endpoints disponibles...")
    try:
        from interviews.urls import router
        
        # Lister les endpoints enregistr√©s
        registered_viewsets = []
        for pattern in router.registry:
            registered_viewsets.append(f"{pattern[0]} -> {pattern[1].__name__}")
        
        print("‚úÖ Endpoints enregistr√©s:")
        for endpoint in registered_viewsets:
            print(f"   - {endpoint}")
            
        # V√©rifier que ai-evaluations est bien enregistr√©
        ai_eval_registered = any('ai-evaluations' in endpoint for endpoint in registered_viewsets)
        if ai_eval_registered:
            print("‚úÖ Endpoint ai-evaluations correctement enregistr√©")
        else:
            print("‚ùå Endpoint ai-evaluations manquant")
            return False
        
    except Exception as e:
        print(f"‚ùå Erreur endpoints: {e}")
        return False
    
    # 7. R√©sum√© des fonctionnalit√©s disponibles
    print("\n7Ô∏è‚É£ R√©sum√© des fonctionnalit√©s disponibles...")
    
    available_endpoints = [
        "GET /api/interviews/ai-evaluations/ - Liste des √©valuations IA",
        "POST /api/interviews/ai-evaluations/evaluate_video/ - D√©clencher √©valuation",
        "POST /api/interviews/ai-evaluations/bulk_evaluate/ - √âvaluation en lot",
        "GET /api/interviews/ai-evaluations/by_campaign/?campaign_id=X - Par campagne",
        "GET /api/interviews/ai-evaluations/by_candidate/?candidate_id=X - Par candidat"
    ]
    
    print("‚úÖ Endpoints API disponibles:")
    for endpoint in available_endpoints:
        print(f"   - {endpoint}")
    
    print("\n" + "=" * 60)
    print("üéâ TEST COMPLET TERMIN√â AVEC SUCC√àS!")
    print("‚úÖ Le syst√®me d'√©valuation IA est op√©rationnel")
    print("\nüìã PROCHAINES √âTAPES RECOMMAND√âES:")
    print("   1. Configurer GOOGLE_GEMINI_API_KEY dans les variables d'environnement")
    print("   2. Tester l'√©valuation IA sur une vraie vid√©o")
    print("   3. Int√©grer l'interface frontend pour afficher les r√©sultats")
    print("   4. Optimiser les performances pour le traitement en lot")
    
    return True

def test_api_example():
    """Exemple d'utilisation de l'API d'√©valuation IA"""
    
    print("\n" + "=" * 60)
    print("üìñ EXEMPLE D'UTILISATION DE L'API")
    print("=" * 60)
    
    # Exemple de payload pour d√©clencher une √©valuation
    evaluate_payload = {
        "interview_answer_id": 1,
        "force_reevaluation": False
    }
    
    print("\nüîß Exemple de requ√™te pour √©valuer une vid√©o:")
    print("POST /api/interviews/ai-evaluations/evaluate_video/")
    print(f"Body: {json.dumps(evaluate_payload, indent=2)}")
    
    # Exemple de payload pour √©valuation en lot
    bulk_payload = {
        "campaign_id": 1,
        "candidate_ids": [1, 2, 3],
        "force_reevaluation": False
    }
    
    print("\nüîß Exemple de requ√™te pour √©valuation en lot:")
    print("POST /api/interviews/ai-evaluations/bulk_evaluate/")
    print(f"Body: {json.dumps(bulk_payload, indent=2)}")
    
    print("\nüîß Exemple de requ√™te pour r√©cup√©rer les √©valuations:")
    print("GET /api/interviews/ai-evaluations/by_campaign/?campaign_id=1")
    print("GET /api/interviews/ai-evaluations/by_candidate/?candidate_id=1")

if __name__ == "__main__":
    try:
        success = test_ai_evaluation_system()
        if success:
            test_api_example()
        else:
            print("\n‚ùå Des erreurs ont √©t√© d√©tect√©es dans le syst√®me")
            sys.exit(1)
    except Exception as e:
        print(f"\nüí• ERREUR CRITIQUE: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
