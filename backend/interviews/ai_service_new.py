import os
import json
import logging
import re
import random
from typing import List, Dict, Any, Optional
from django.conf import settings
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold

logger = logging.getLogger(__name__)

class AIInterviewQuestionGenerator:
    """
    Service de g√©n√©ration de questions d'entretien avec Google Gemini
    15 requ√™tes/minute gratuites - Excellent pour JobGate
    """
    
    def __init__(self):
        # Chercher la cl√© API dans plusieurs variables d'environnement
        self.api_key = (
            getattr(settings, 'GOOGLE_API_KEY', None) or 
            getattr(settings, 'GOOGLE_GEMINI_API_KEY', None) or 
            os.getenv('GOOGLE_API_KEY') or 
            os.getenv('GOOGLE_GEMINI_API_KEY')
        )
        self.use_gemini = getattr(settings, 'USE_GEMINI', True) or getattr(settings, 'USE_GOOGLE_GEMINI', True)
        
        # Banque de questions comportementales statiques
        self.static_behavioral_questions = [
            # TRAVAIL EN √âQUIPE
            "Parle-moi d'une fois o√π tu as d√ª collaborer avec une √©quipe difficile. Comment as-tu g√©r√© la situation ?",
            "Donne un exemple d'un projet o√π ton r√¥le √©tait crucial pour la r√©ussite collective.",
            
            # GESTION DES CONFLITS
            "Raconte une situation o√π tu n'√©tais pas d'accord avec ton sup√©rieur ou un coll√®gue. Comment as-tu r√©agi ?",
            "D√©cris un conflit que tu as aid√© √† r√©soudre.",
            
            # PRISE D'INITIATIVE
            "Donne un exemple o√π tu as pris une d√©cision sans attendre d'instructions.",
            "Parle-moi d'une am√©lioration que tu as propos√©e et mise en place dans ton travail.",
            
            # GESTION DU STRESS & DES PRIORIT√âS
            "Raconte une exp√©rience o√π tu as d√ª g√©rer plusieurs t√¢ches urgentes en m√™me temps.",
            "Comment as-tu r√©agi dans une situation de forte pression avec peu de temps ?",
            
            # R√âSOLUTION DE PROBL√àME
            "Donne un exemple d'un probl√®me complexe que tu as r√©solu. Quelle a √©t√© ton approche ?",
            "D√©cris une situation o√π tu n'avais pas toutes les informations n√©cessaires mais tu as d√ª agir rapidement.",
            
            # ADAPTABILIT√â & APPRENTISSAGE
            "Parle-moi d'une fois o√π tu as d√ª apprendre une nouvelle comp√©tence rapidement pour accomplir une mission.",
            "Comment t'es-tu adapt√© √† un changement impr√©vu au travail ?"
        ]
        
        try:
            # Configuration Gemini
            if self.api_key:
                genai.configure(api_key=self.api_key)
            
            # Configuration de g√©n√©ration
            generation_config = {
                "temperature": 0.7,
                "top_p": 0.8,
                "top_k": 40,
                "max_output_tokens": 2048,
            }
            
            # Configuration de s√©curit√© (permissive pour questions d'entretien)
            safety_settings = {
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            }
            
            self.model = genai.GenerativeModel(
                model_name="gemini-1.5-flash",
                generation_config=generation_config,
                safety_settings=safety_settings
            )
            
            logger.info("‚úÖ Google Gemini initialis√© avec succ√®s (gratuit)")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation Gemini: {e}")
            self.model = None
    
    def generate_questions(self, offer_title: str, offer_description: str, 
                          number_of_questions: int = 5, difficulty: str = 'medium',
                          requirements: str = '', behavioral_count: int = None, 
                          technical_count: int = None) -> List[Dict[str, Any]]:
        """
        G√©n√®re des questions d'entretien personnalis√©es avec Google Gemini
        """
        logger.info(f"ü§ñ G√©n√©ration de {number_of_questions} questions avec Gemini")
        logger.info(f"üìã Poste: {offer_title}")
        logger.info(f"üéØ Difficult√©: {difficulty}")
        logger.info(f"üîß Mod√®le initialis√©: {self.model is not None}")
        logger.info(f"üîë API Key pr√©sente: {self.api_key is not None}")
        
        # Validation des param√®tres
        if not offer_title or len(offer_title.strip()) < 3:
            logger.error("‚ùå Titre de l'offre trop court")
            raise ValueError("Le titre de l'offre doit contenir au moins 3 caract√®res")
        
        if not offer_description or len(offer_description.strip()) < 20:
            logger.error("‚ùå Description de l'offre trop courte")
            raise ValueError("La description de l'offre doit contenir au moins 20 caract√®res")
        
        if number_of_questions < 1 or number_of_questions > 10:
            logger.error("‚ùå Nombre de questions invalide")
            raise ValueError("Le nombre de questions doit √™tre entre 1 et 10")
        
        # Cr√©er la question obligatoire
        mandatory_question = {
            "question": "Pr√©sentez-vous et dites-nous pourquoi vous choisissez de nous rejoindre ?",
            "type": "comportementale",
            "difficulty": difficulty,
            "expected_duration": 180,
            "skills_assessed": ["communication", "motivation", "pr√©sentation"],
            "order": 1,
            "generated_by": "mandatory",
            "offer_title": offer_title
        }
        
        # Gestion des compteurs sp√©cifiques
        if behavioral_count is not None and technical_count is not None:
            logger.info(f"üéØ Mode compteurs sp√©cifiques: {behavioral_count} comportementales + {technical_count} techniques")
            
            # Calculer le nombre total de questions IA √† g√©n√©rer
            ai_questions_count = behavioral_count + technical_count
            
            if ai_questions_count == 0:
                logger.info("‚ö†Ô∏è Aucune question IA demand√©e, retour de la question obligatoire uniquement")
                return [mandatory_question]
            
            logger.info(f"ü§ñ G√©n√©ration de {ai_questions_count} questions IA")
        else:
            # Mode classique
            ai_questions_count = number_of_questions - 1  # -1 pour la question obligatoire
            behavioral_count = max(1, ai_questions_count // 2)  # Au moins 1 comportementale
            technical_count = ai_questions_count - behavioral_count
        
        # Construire la liste finale des questions
        final_questions = [mandatory_question]
        
        # Ajouter les questions comportementales statiques si demand√©es
        if behavioral_count > 0:
            behavioral_questions = self._get_static_behavioral_questions(behavioral_count)
            final_questions.extend(behavioral_questions)
        
        # G√©n√©rer les questions techniques avec l'IA si n√©cessaire
        if technical_count > 0:
            technical_questions = self._generate_technical_questions(
                offer_title, offer_description, technical_count, 
                difficulty, requirements
            )
            final_questions.extend(technical_questions)
        
        logger.info(f"‚úÖ {len(final_questions)} questions g√©n√©r√©es au total")
        return final_questions
    
    def _get_static_behavioral_questions(self, count: int) -> List[Dict[str, Any]]:
        """S√©lectionne al√©atoirement des questions comportementales statiques"""
        logger.info(f"üìã S√©lection de {count} questions comportementales statiques")
        
        # S√©lection al√©atoire sans r√©p√©tition
        selected_questions = random.sample(self.static_behavioral_questions, min(count, len(self.static_behavioral_questions)))
        
        behavioral_questions = []
        for i, question_text in enumerate(selected_questions, 2):  # Start at 2 (after mandatory)
            question = {
                "question": question_text,
                "type": "comportementale",
                "difficulty": "medium",
                "expected_duration": 120,
                "skills_assessed": ["comportement", "exp√©rience", "soft_skills"],
                "order": i,
                "generated_by": "static_behavioral"
            }
            behavioral_questions.append(question)
            logger.info(f"‚úÖ Question comportementale {i}: {question_text[:50]}...")
        
        return behavioral_questions
    
    def _generate_technical_questions(self, offer_title: str, offer_description: str, 
                                    count: int, difficulty: str, requirements: str) -> List[Dict[str, Any]]:
        """G√©n√®re uniquement des questions techniques avec l'IA"""
        logger.info(f"ü§ñ G√©n√©ration de {count} questions techniques avec IA")
        
        # Prompt sp√©cialis√© pour questions techniques uniquement
        prompt = f"""Tu es un expert RH sp√©cialis√© dans les entretiens techniques.

POSTE: {offer_title}
DESCRIPTION: {offer_description}
EXIGENCES: {requirements}
NIVEAU: {difficulty}

G√âN√àRE EXACTEMENT {count} QUESTIONS TECHNIQUES COURTES (1-2 lignes max).

FORMAT JSON STRICT:
[
  {{
    "question": "Question technique sp√©cifique au poste",
    "type": "technique"
  }}
]

EXIGENCES:
- Questions TECHNIQUES uniquement (programmation, outils, m√©thodologies)
- Sp√©cifiques au domaine du poste
- Courtes et pr√©cises
- Niveau {difficulty}
"""
        
        try:
            logger.info("üîÑ G√©n√©ration questions techniques avec Gemini...")
            response = self.model.generate_content(prompt)
            
            if not response or not response.text:
                raise ValueError("R√©ponse vide de Gemini")
            
            # Parse JSON
            questions_data = self._parse_json_response(response.text)
            
            # Formater les questions techniques
            technical_questions = []
            start_order = 2 + count  # After mandatory + behavioral questions
            
            for i, q_data in enumerate(questions_data[:count]):
                question = {
                    "question": q_data.get('question', ''),
                    "type": "technique",
                    "difficulty": "medium",
                    "expected_duration": 180,
                    "skills_assessed": ["technique"],
                    "order": start_order + i,
                    "generated_by": "ai_technical"
                }
                technical_questions.append(question)
                logger.info(f"‚úÖ Question technique {start_order + i}: {question['question'][:50]}...")
            
            return technical_questions
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration questions techniques: {e}")
            # Fallback: questions techniques g√©n√©riques
            return self._create_fallback_technical_questions(count, offer_title)
    
    def _parse_json_response(self, response_text: str) -> List[Dict]:
        """Parse la r√©ponse JSON de l'IA"""
        try:
            # Nettoyer la r√©ponse
            cleaned_text = response_text.strip()
            if cleaned_text.startswith('```json'):
                cleaned_text = cleaned_text[7:]
            if cleaned_text.endswith('```'):
                cleaned_text = cleaned_text[:-3]
            
            # Parser JSON
            questions_data = json.loads(cleaned_text.strip())
            
            if not isinstance(questions_data, list):
                raise ValueError("La r√©ponse doit √™tre une liste")
            
            return questions_data
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Erreur parsing JSON: {e}")
            logger.error(f"R√©ponse brute: {response_text[:200]}...")
            raise ValueError("Format JSON invalide dans la r√©ponse de l'IA")
    
    def _create_fallback_technical_questions(self, count: int, offer_title: str) -> List[Dict[str, Any]]:
        """Cr√©e des questions techniques de fallback"""
        fallback_questions = [
            "Quelles sont les principales technologies que vous ma√Ætrisez pour ce poste ?",
            "Comment abordez-vous la r√©solution d'un probl√®me technique complexe ?",
            "D√©crivez votre exp√©rience avec les outils mentionn√©s dans l'offre.",
            "Quelles sont vos m√©thodes pour rester √† jour techniquement ?",
            "Comment g√©rez-vous la qualit√© du code dans vos projets ?"
        ]
        
        technical_questions = []
        for i in range(min(count, len(fallback_questions))):
            question = {
                "question": fallback_questions[i],
                "type": "technique",
                "difficulty": "medium",
                "expected_duration": 180,
                "skills_assessed": ["technique"],
                "order": i + 2,
                "generated_by": "fallback_technical"
            }
            technical_questions.append(question)
        
        return technical_questions
