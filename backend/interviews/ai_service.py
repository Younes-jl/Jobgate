import os
import json
import logging
import re
from typing import List, Dict, Any, Optional
from django.conf import settings
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold

logger = logging.getLogger(__name__)

class AIInterviewQuestionGenerator:
    """
    Service de g√©n√©ration de questions d'entretien avec Google Gemini
    15 requ√™tes/minute gratuites - Excellent pour JobGate
    """
    
    def __init__(self):
        self.api_key = getattr(settings, 'GOOGLE_GEMINI_API_KEY', None) or os.getenv('GOOGLE_GEMINI_API_KEY')
        self.use_gemini = getattr(settings, 'USE_GOOGLE_GEMINI', True)
        
        if self.use_gemini and self.api_key and self.api_key != 'your_google_gemini_api_key_here':
            self._initialize_gemini()
        else:
            logger.info("üîÑ Google Gemini non configur√©, utilisation du mode fallback")
            self.model = None
    
    def _initialize_gemini(self):
        """Initialise le client Google Gemini"""
        try:
            genai.configure(api_key=self.api_key)
            
            # Configuration du mod√®le Gemini-1.5-flash (gratuit)
            generation_config = {
                "temperature": 0.7,
                "top_p": 0.8,
                "top_k": 40,
                "max_output_tokens": 2048,
            }
            
            # Configuration de s√©curit√© (permissive pour questions d'entretien)
            safety_settings = {
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            }
            
            self.model = genai.GenerativeModel(
                model_name="gemini-1.5-flash",
                generation_config=generation_config,
                safety_settings=safety_settings
            )
            
            logger.info("‚úÖ Google Gemini initialis√© avec succ√®s (gratuit)")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation Gemini: {e}")
            self.model = None
    
    def generate_questions(self, offer_title: str, offer_description: str, 
                          number_of_questions: int = 5, difficulty: str = 'medium') -> List[Dict[str, Any]]:
        """
        G√©n√®re des questions d'entretien personnalis√©es avec Google Gemini
        
        Args:
            offer_title: Titre de l'offre d'emploi
            offer_description: Description d√©taill√©e du poste
            number_of_questions: Nombre de questions √† g√©n√©rer (3-10)
            difficulty: Niveau de difficult√© (easy/medium/hard)
        
        Returns:
            Liste de questions format√©es pour JobGate
        """
        logger.info(f"ü§ñ G√©n√©ration de {number_of_questions} questions avec Gemini")
        logger.info(f"üìã Poste: {offer_title}")
        logger.info(f"üéØ Difficult√©: {difficulty}")
        
        # Validation des param√®tres
        if not offer_title or len(offer_title.strip()) < 3:
            logger.error("‚ùå Titre de l'offre trop court")
            return self._get_fallback_questions(number_of_questions)
        
        if not offer_description or len(offer_description.strip()) < 20:
            logger.error("‚ùå Description de l'offre trop courte")
            return self._get_fallback_questions(number_of_questions)
        
        number_of_questions = max(3, min(10, number_of_questions))
        
        if self.model:
            try:
                return self._generate_with_gemini(offer_title, offer_description, 
                                                number_of_questions, difficulty)
            except Exception as e:
                logger.error(f"‚ùå Erreur Gemini: {e}")
                logger.info("üîÑ Basculement vers le fallback")
                return self._get_fallback_questions(number_of_questions)
        else:
            logger.info("üîÑ Utilisation du syst√®me de fallback")
            return self._get_fallback_questions(number_of_questions)
    
    def _generate_with_gemini(self, offer_title: str, offer_description: str, 
                             num_questions: int, difficulty: str) -> List[Dict[str, Any]]:
        """G√©n√®re les questions avec l'API Google Gemini"""
        
        # Mapping des difficult√©s
        difficulty_mapping = {
            'easy': 'd√©butant - questions g√©n√©rales et basiques',
            'medium': 'interm√©diaire - questions techniques mod√©r√©es', 
            'hard': 'avanc√© - questions techniques approfondies et cas complexes'
        }
        difficulty_desc = difficulty_mapping.get(difficulty, difficulty_mapping['medium'])
        
        # Prompt optimis√© pour Gemini
        prompt = f"""
Vous √™tes un expert en recrutement RH. G√©n√©rez {num_questions} questions d'entretien vid√©o professionnelles.

**POSTE √Ä POURVOIR:**
Titre: {offer_title}
Description: {offer_description}

**INSTRUCTIONS:**
- Niveau de difficult√©: {difficulty_desc}
- Questions adapt√©es sp√©cifiquement √† ce poste
- M√©lange de questions techniques, comportementales et situationnelles
- Dur√©e de r√©ponse recommand√©e: 60-180 secondes par question
- Questions ouvertes permettant au candidat de d√©montrer ses comp√©tences

**FORMAT DE R√âPONSE (OBLIGATOIRE - JSON strict):**
```json
[
  {{
    "question": "Votre question ici",
    "type": "technique|comportementale|situationnelle",
    "expected_duration": 120,
    "difficulty_level": "{difficulty}",
    "skills_assessed": ["comp√©tence1", "comp√©tence2"]
  }}
]
```

G√©n√©rez exactement {num_questions} questions uniques et pertinentes.
"""
        
        try:
            logger.info("üîÑ Envoi de la requ√™te √† Google Gemini...")
            
            # G√©n√©ration avec Gemini
            response = self.model.generate_content(prompt)
            
            if not response or not response.text:
                logger.error("‚ùå R√©ponse vide de Gemini")
                return self._get_fallback_questions(num_questions)
            
            logger.info("‚úÖ R√©ponse re√ßue de Gemini")
            
            # Extraction du JSON de la r√©ponse
            questions_data = self._parse_gemini_response(response.text)
            
            if not questions_data:
                logger.error("‚ùå Impossible de parser la r√©ponse Gemini")
                return self._get_fallback_questions(num_questions)
            
            # Validation et formatage
            formatted_questions = self._format_questions_for_jobgate(
                questions_data, offer_title, difficulty
            )
            
            logger.info(f"‚úÖ {len(formatted_questions)} questions g√©n√©r√©es avec Gemini")
            return formatted_questions
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'appel Gemini: {e}")
            raise
    
    def _parse_gemini_response(self, response_text: str) -> Optional[List[Dict]]:
        """Parse la r√©ponse JSON de Gemini"""
        try:
            # Chercher le bloc JSON dans la r√©ponse
            json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
            if json_match:
                json_text = json_match.group(1)
            else:
                # Si pas de bloc markdown, essayer de parser directement
                json_text = response_text.strip()
            
            # Parser le JSON
            questions_data = json.loads(json_text)
            
            if isinstance(questions_data, list):
                return questions_data
            else:
                logger.error(f"‚ùå Format de r√©ponse incorrect: {type(questions_data)}")
                return None
                
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Erreur JSON: {e}")
            logger.error(f"R√©ponse brute: {response_text[:500]}...")
            return None
        except Exception as e:
            logger.error(f"‚ùå Erreur parsing: {e}")
            return None
    
    def _format_questions_for_jobgate(self, questions_data: List[Dict], 
                                     offer_title: str, difficulty: str) -> List[Dict[str, Any]]:
        """Formate les questions pour l'API JobGate"""
        formatted_questions = []
        
        for i, q_data in enumerate(questions_data):
            try:
                question_text = q_data.get('question', '').strip()
                if not question_text:
                    continue
                
                formatted_question = {
                    "question": question_text,
                    "type": q_data.get('type', 'comportementale'),
                    "expected_duration": q_data.get('expected_duration', 120),
                    "difficulty_level": difficulty,
                    "skills_assessed": q_data.get('skills_assessed', []),
                    "order": i + 1,
                    "generated_by": "google_gemini",
                    "offer_title": offer_title
                }
                
                formatted_questions.append(formatted_question)
                
            except Exception as e:
                logger.error(f"‚ùå Erreur formatage question {i}: {e}")
                continue
        
        return formatted_questions
    
    def _get_fallback_questions(self, num_questions: int) -> List[Dict[str, Any]]:
        """Questions de fallback de haute qualit√© si Gemini n'est pas disponible"""
        
        fallback_questions = [
            {
                "question": "Pouvez-vous vous pr√©senter en quelques minutes et expliquer pourquoi vous souhaitez rejoindre notre entreprise ?",
                "type": "comportementale",
                "expected_duration": 120,
                "difficulty_level": "easy",
                "skills_assessed": ["communication", "motivation"],
                "order": 1
            },
            {
                "question": "D√©crivez-moi un projet professionnel dont vous √™tes particuli√®rement fier. Quel √©tait votre r√¥le et quels d√©fis avez-vous surmont√©s ?",
                "type": "technique",
                "expected_duration": 180,
                "difficulty_level": "medium",
                "skills_assessed": ["gestion de projet", "r√©solution de probl√®mes"],
                "order": 2
            },
            {
                "question": "Comment g√©rez-vous les priorit√©s quand vous avez plusieurs t√¢ches importantes √† accomplir en m√™me temps ?",
                "type": "comportementale",
                "expected_duration": 120,
                "difficulty_level": "medium",
                "skills_assessed": ["organisation", "gestion du temps"],
                "order": 3
            },
            {
                "question": "Parlez-moi d'une situation o√π vous avez d√ª apprendre rapidement une nouvelle technologie ou comp√©tence. Comment avez-vous proc√©d√© ?",
                "type": "technique",
                "expected_duration": 150,
                "difficulty_level": "medium",
                "skills_assessed": ["apprentissage", "adaptabilit√©"],
                "order": 4
            },
            {
                "question": "D√©crivez un conflit professionnel que vous avez v√©cu et comment vous l'avez r√©solu.",
                "type": "situationnelle",
                "expected_duration": 180,
                "difficulty_level": "hard",
                "skills_assessed": ["gestion des conflits", "communication"],
                "order": 5
            },
            {
                "question": "Quelles sont vos principales forces professionnelles et comment les mettriez-vous au service de notre √©quipe ?",
                "type": "comportementale",
                "expected_duration": 120,
                "difficulty_level": "easy",
                "skills_assessed": ["auto-√©valuation", "collaboration"],
                "order": 6
            },
            {
                "question": "O√π vous voyez-vous dans 3 ans et comment ce poste s'inscrit-il dans votre parcours professionnel ?",
                "type": "comportementale",
                "expected_duration": 120,
                "difficulty_level": "medium",
                "skills_assessed": ["vision", "ambition"],
                "order": 7
            }
        ]
        
        # Ajouter les m√©tadonn√©es de fallback
        for question in fallback_questions[:num_questions]:
            question.update({
                "generated_by": "fallback_system",
                "offer_title": "Poste g√©n√©rique"
            })
        
        logger.info(f"üîÑ Utilisation de {num_questions} questions de fallback")
        return fallback_questions[:num_questions]

# Instance globale pour l'utilisation dans les vues
ai_generator = AIInterviewQuestionGenerator()

# Fonction utilitaire pour l'analyse de qualit√© (bonus)
def analyze_question_quality(questions: List[Dict]) -> Dict[str, Any]:
    """Analyse la qualit√© des questions g√©n√©r√©es"""
    if not questions:
        return {"score": 0, "feedback": "Aucune question √† analyser"}
    
    total_score = 0
    feedback = []
    
    # Crit√®res d'√©valuation
    question_types = set(q.get('type', '') for q in questions)
    if len(question_types) >= 2:
        total_score += 25
        feedback.append("‚úÖ Bonne vari√©t√© de types de questions")
    
    avg_duration = sum(q.get('expected_duration', 120) for q in questions) / len(questions)
    if 90 <= avg_duration <= 180:
        total_score += 25
        feedback.append("‚úÖ Dur√©e appropri√©e pour les r√©ponses")
    
    if len(questions) >= 3:
        total_score += 25
        feedback.append("‚úÖ Nombre de questions suffisant")
    
    has_skills = any(q.get('skills_assessed') for q in questions)
    if has_skills:
        total_score += 25
        feedback.append("‚úÖ Comp√©tences √©valu√©es d√©finies")
    
    return {
        "score": total_score,
        "feedback": feedback,
        "question_count": len(questions),
        "avg_duration": round(avg_duration),
        "question_types": list(question_types)
    }
