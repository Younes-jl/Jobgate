import os
import json
import logging
import re
import random
from typing import List, Dict, Any, Optional
from django.conf import settings
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold

logger = logging.getLogger(__name__)

class AIInterviewQuestionGenerator:
    """
    Service de g√©n√©ration de questions d'entretien avec Google Gemini
    15 requ√™tes/minute gratuites - Excellent pour JobGate
    """
    
    def __init__(self):
        # Chercher la cl√© API dans plusieurs variables d'environnement
        self.api_key = (
            getattr(settings, 'GOOGLE_API_KEY', None) or 
            getattr(settings, 'GOOGLE_GEMINI_API_KEY', None) or 
            os.getenv('GOOGLE_API_KEY') or 
            os.getenv('GOOGLE_GEMINI_API_KEY')
        )
        self.use_gemini = getattr(settings, 'USE_GEMINI', True) or getattr(settings, 'USE_GOOGLE_GEMINI', True)
        
        # Banque de questions comportementales statiques
        self.static_behavioral_questions = [
            # TRAVAIL EN √âQUIPE
            "Parle-moi d'une fois o√π tu as d√ª collaborer avec une √©quipe difficile. Comment as-tu g√©r√© la situation ?",
            "Donne un exemple d'un projet o√π ton r√¥le √©tait crucial pour la r√©ussite collective.",
            
            # GESTION DES CONFLITS
            "Raconte une situation o√π tu n'√©tais pas d'accord avec ton sup√©rieur ou un coll√®gue. Comment as-tu r√©agi ?",
            "D√©cris un conflit que tu as aid√© √† r√©soudre.",
            
            # PRISE D'INITIATIVE
            "Donne un exemple o√π tu as pris une d√©cision sans attendre d'instructions.",
            "Parle-moi d'une am√©lioration que tu as propos√©e et mise en place dans ton travail.",
            
            # GESTION DU STRESS & DES PRIORIT√âS
            "Raconte une exp√©rience o√π tu as d√ª g√©rer plusieurs t√¢ches urgentes en m√™me temps.",
            "Comment as-tu r√©agi dans une situation de forte pression avec peu de temps ?",
            
            # R√âSOLUTION DE PROBL√àME
            "Donne un exemple d'un probl√®me complexe que tu as r√©solu. Quelle a √©t√© ton approche ?",
            "D√©cris une situation o√π tu n'avais pas toutes les informations n√©cessaires mais tu as d√ª agir rapidement.",
            
            # ADAPTABILIT√â & APPRENTISSAGE
            "Parle-moi d'une fois o√π tu as d√ª apprendre une nouvelle comp√©tence rapidement pour accomplir une mission.",
            "Comment t'es-tu adapt√© √† un changement impr√©vu au travail ?"
        ]
        
        try:
            # Configuration Gemini
            if self.api_key:
                genai.configure(api_key=self.api_key)
            
            # Configuration de g√©n√©ration
            generation_config = {
                "temperature": 0.7,
                "top_p": 0.8,
                "top_k": 40,
                "max_output_tokens": 2048,
            }
            
            # Configuration de s√©curit√© (permissive pour questions d'entretien)
            safety_settings = {
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            }
            
            self.model = genai.GenerativeModel(
                model_name="gemini-1.5-flash",
                generation_config=generation_config,
                safety_settings=safety_settings
            )
            
            logger.info("‚úÖ Google Gemini initialis√© avec succ√®s (gratuit)")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation Gemini: {e}")
            self.model = None
    
    def generate_questions(self, offer_title: str, offer_description: str, 
                          number_of_questions: int = 5, difficulty: str = 'medium',
                          requirements: str = '', behavioral_count: int = None, 
                          technical_count: int = None, existing_questions_count: int = 0) -> List[Dict[str, Any]]:
        """
        G√©n√®re des questions d'entretien personnalis√©es avec Google Gemini
        """
        logger.info(f"ü§ñ G√©n√©ration de {number_of_questions} questions avec Gemini")
        logger.info(f"üìã Poste: {offer_title}")
        logger.info(f"üéØ Difficult√©: {difficulty}")
        logger.info(f"üìä Questions existantes: {existing_questions_count}")
        logger.info(f"üîß Mod√®le initialis√©: {self.model is not None}")
        logger.info(f"üîë API Key pr√©sente: {self.api_key is not None}")
        
        # Calculer le nombre r√©el de questions √† g√©n√©rer
        actual_questions_needed = max(0, number_of_questions - existing_questions_count)
        logger.info(f"üéØ Questions IA √† g√©n√©rer: {actual_questions_needed} (demand√©: {number_of_questions} - existantes: {existing_questions_count})")
        
        # Si aucune question √† g√©n√©rer, retourner une liste vide
        if actual_questions_needed == 0:
            logger.info("‚úÖ Aucune question √† g√©n√©rer, questions existantes suffisantes")
            return []
        
        # Validation des param√®tres
        if not offer_title or len(offer_title.strip()) < 3:
            logger.error("‚ùå Titre de l'offre trop court")
            raise ValueError("Le titre de l'offre doit contenir au moins 3 caract√®res")
        
        if not offer_description or len(offer_description.strip()) < 20:
            logger.error("‚ùå Description de l'offre trop courte")
            raise ValueError("La description de l'offre doit contenir au moins 20 caract√®res")
        
        # Gestion des compteurs sp√©cifiques
        if behavioral_count is not None and technical_count is not None:
            logger.info(f"üéØ Mode compteurs sp√©cifiques: {behavioral_count} comportementales + {technical_count} techniques")
            
            # Ajuster les compteurs selon les questions existantes et le nombre demand√©
            total_requested = behavioral_count + technical_count
            if total_requested > actual_questions_needed:
                # R√©duire proportionnellement
                ratio = actual_questions_needed / total_requested
                behavioral_count = int(behavioral_count * ratio)
                technical_count = actual_questions_needed - behavioral_count
            
            if behavioral_count + technical_count == 0:
                logger.info("‚ö†Ô∏è Aucune question IA demand√©e apr√®s ajustement")
                return []
            
            logger.info(f"ü§ñ G√©n√©ration de {behavioral_count + technical_count} questions IA ajust√©es")
        else:
            # Mode classique - utiliser le nombre ajust√©
            behavioral_count = max(1, actual_questions_needed // 2) if actual_questions_needed > 0 else 0
            technical_count = actual_questions_needed - behavioral_count
        
        # Construire la liste finale des questions (sans question obligatoire car elle existe d√©j√†)
        final_questions = []
        
        # Ajouter les questions comportementales statiques si demand√©es
        if behavioral_count > 0:
            behavioral_questions = self._get_static_behavioral_questions(behavioral_count)
            final_questions.extend(behavioral_questions)
        
        # G√©n√©rer les questions techniques avec l'IA si n√©cessaire
        if technical_count > 0:
            technical_questions = self._generate_technical_questions(
                offer_title, offer_description, technical_count, 
                difficulty, requirements
            )
            final_questions.extend(technical_questions)
        
        logger.info(f"‚úÖ {len(final_questions)} questions g√©n√©r√©es au total")
        return final_questions
    
    def _get_static_behavioral_questions(self, count: int) -> List[Dict[str, Any]]:
        """S√©lectionne al√©atoirement des questions comportementales statiques"""
        logger.info(f"üìã S√©lection de {count} questions comportementales statiques")
        
        # S√©lection al√©atoire sans r√©p√©tition
        selected_questions = random.sample(self.static_behavioral_questions, min(count, len(self.static_behavioral_questions)))
        
        behavioral_questions = []
        for i, question_text in enumerate(selected_questions, 2):  # Start at 2 (after mandatory)
            question = {
                "question": question_text,
                "type": "comportementale",
                "difficulty": "medium",
                "expected_duration": 120,
                "skills_assessed": ["comportement", "exp√©rience", "soft_skills"],
                "order": i,
                "generated_by": "static_behavioral"
            }
            behavioral_questions.append(question)
            logger.info(f"‚úÖ Question comportementale {i}: {question_text[:50]}...")
        
        return behavioral_questions
    
    def _generate_technical_questions(self, offer_title: str, offer_description: str, 
                                    count: int, difficulty: str, requirements: str) -> List[Dict[str, Any]]:
        """G√©n√®re uniquement des questions techniques avec l'IA"""
        logger.info(f"ü§ñ G√©n√©ration de {count} questions techniques avec IA")
        
        # Prompt sp√©cialis√© pour questions techniques uniquement
        prompt = f"""Tu es un expert RH sp√©cialis√© dans les entretiens techniques.

POSTE: {offer_title}
DESCRIPTION: {offer_description}
EXIGENCES: {requirements}
NIVEAU: {difficulty}

G√âN√àRE EXACTEMENT {count} QUESTIONS TECHNIQUES COURTES (1-2 lignes max).

FORMAT JSON STRICT:
[
  {{
    "question": "Question technique sp√©cifique au poste",
    "type": "technique"
  }}
]

EXIGENCES:
- Questions TECHNIQUES uniquement (programmation, outils, m√©thodologies)
- Sp√©cifiques au domaine du poste
- Courtes et pr√©cises
- Niveau {difficulty}
"""
        
        try:
            logger.info("üîÑ G√©n√©ration questions techniques avec Gemini...")
            response = self.model.generate_content(prompt)
            
            if not response or not response.text:
                raise ValueError("R√©ponse vide de Gemini")
            
            # Parse JSON
            questions_data = self._parse_json_response(response.text)
            
            # Formater les questions techniques
            technical_questions = []
            start_order = 2 + count  # After mandatory + behavioral questions
            
            for i, q_data in enumerate(questions_data[:count]):
                question = {
                    "question": q_data.get('question', ''),
                    "type": "technique",
                    "difficulty": "medium",
                    "expected_duration": 180,
                    "skills_assessed": ["technique"],
                    "order": start_order + i,
                    "generated_by": "ai_technical"
                }
                technical_questions.append(question)
                logger.info(f"‚úÖ Question technique {start_order + i}: {question['question'][:50]}...")
            
            return technical_questions
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration questions techniques: {e}")
            # Fallback: questions techniques g√©n√©riques
            return self._create_fallback_technical_questions(count, offer_title)
    
    def _parse_json_response(self, response_text: str) -> List[Dict]:
        """Parse la r√©ponse JSON de l'IA"""
        try:
            # Nettoyer la r√©ponse
            cleaned_text = response_text.strip()
            if cleaned_text.startswith('```json'):
                cleaned_text = cleaned_text[7:]
            if cleaned_text.endswith('```'):
                cleaned_text = cleaned_text[:-3]
            
            # Parser JSON
            questions_data = json.loads(cleaned_text.strip())
            
            if not isinstance(questions_data, list):
                raise ValueError("La r√©ponse doit √™tre une liste")
            
            return questions_data
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Erreur parsing JSON: {e}")
            logger.error(f"R√©ponse brute: {response_text[:200]}...")
            raise ValueError("Format JSON invalide dans la r√©ponse de l'IA")
    
    def _create_fallback_technical_questions(self, count: int, offer_title: str) -> List[Dict[str, Any]]:
        """Cr√©e des questions techniques de fallback"""
        fallback_questions = [
            "Quelles sont les principales technologies que vous ma√Ætrisez pour ce poste ?",
            "Comment abordez-vous la r√©solution d'un probl√®me technique complexe ?",
            "D√©crivez votre exp√©rience avec les outils mentionn√©s dans l'offre.",
            "Quelles sont vos m√©thodes pour rester √† jour techniquement ?",
            "Comment g√©rez-vous la qualit√© du code dans vos projets ?"
        ]
        
        technical_questions = []
        for i in range(min(count, len(fallback_questions))):
            question = {
                "question": fallback_questions[i],
                "type": "technique",
                "difficulty": "medium",
                "expected_duration": 180,
                "skills_assessed": ["technique"],
                "order": i + 2,
                "generated_by": "fallback_technical"
            }
            technical_questions.append(question)
        
        return technical_questions


def analyze_question_quality(questions: List[Dict[str, Any]], offer_title: str, requirements: str) -> Dict[str, Any]:
    """
    Analyse la qualit√© des questions g√©n√©r√©es pour un poste donn√©
    
    Args:
        questions: Liste des questions √† analyser
        offer_title: Titre du poste
        requirements: Exigences du poste
    
    Returns:
        Dict contenant l'analyse de qualit√©
    """
    logger.info(f"üîç Analyse de qualit√© pour {len(questions)} questions")
    
    analysis = {
        "total_questions": len(questions),
        "behavioral_count": len([q for q in questions if q.get('type') == 'comportementale']),
        "technical_count": len([q for q in questions if q.get('type') == 'technique']),
        "quality_score": 85,  # Score par d√©faut pour les questions statiques
        "recommendations": [],
        "strengths": [
            "Questions comportementales bas√©es sur des situations concr√®tes",
            "Format coh√©rent et professionnel",
            "Dur√©es d'entretien appropri√©es"
        ]
    }
    
    # V√©rifications de base
    if analysis["behavioral_count"] == 0:
        analysis["recommendations"].append("Ajouter des questions comportementales pour √©valuer les soft skills")
        analysis["quality_score"] -= 10
    
    if analysis["technical_count"] == 0 and "technique" in offer_title.lower():
        analysis["recommendations"].append("Ajouter des questions techniques pour ce poste technique")
        analysis["quality_score"] -= 5
    
    # Questions obligatoires
    mandatory_found = any("pr√©sentez-vous" in q.get('question', '').lower() for q in questions)
    if mandatory_found:
        analysis["strengths"].append("Question de pr√©sentation obligatoire pr√©sente")
    else:
        analysis["recommendations"].append("Ajouter la question de pr√©sentation obligatoire")
        analysis["quality_score"] -= 15
    
    logger.info(f"‚úÖ Analyse termin√©e - Score: {analysis['quality_score']}/100")
    return analysis
