"""
Service d'√©valuation IA pour les r√©ponses vid√©o d'entretien.
Int√®gre Whisper pour la transcription et diff√©rents mod√®les IA pour l'analyse.
"""

import os
import tempfile
import time
import logging
from typing import Dict, List, Optional, Tuple
from urllib.parse import urlparse
import requests
import google.generativeai as genai
from django.conf import settings
from django.core.files.storage import default_storage
from django.utils import timezone

# Import optionnel des d√©pendances IA lourdes
try:
    import whisper
    import ffmpeg
    import torch
    from transformers import pipeline
    AI_DEPENDENCIES_AVAILABLE = True
except ImportError as e:
    AI_DEPENDENCIES_AVAILABLE = False
    logging.warning(f"AI dependencies not available: {e}")
    # Cr√©er des objets mock pour √©viter les erreurs
    whisper = None
    ffmpeg = None
    torch = None
    pipeline = None

logger = logging.getLogger(__name__)


class VideoProcessingError(Exception):
    """Exception lev√©e lors d'erreurs de traitement vid√©o"""
    pass


class TranscriptionError(Exception):
    """Exception lev√©e lors d'erreurs de transcription"""
    pass


class AIAnalysisError(Exception):
    """Exception lev√©e lors d'erreurs d'analyse IA"""
    pass


class AIVideoEvaluationService:
    """
    Service principal pour l'√©valuation IA des r√©ponses vid√©o d'entretien.
    
    Fonctionnalit√©s:
    1. T√©l√©chargement de vid√©os depuis Cloudinary
    2. Extraction audio avec FFmpeg
    3. Transcription avec Whisper
    4. Analyse IA avec Gemini ou Hugging Face
    5. G√©n√©ration de scores et feedback
    """
    
    def __init__(self):
        self.whisper_model = None
        self.hf_pipeline = None
        self._setup_ai_providers()
    
    def _setup_ai_providers(self):
        """Configure les fournisseurs IA selon les settings"""
        # Configuration Gemini
        if hasattr(settings, 'GOOGLE_GEMINI_API_KEY') and settings.GOOGLE_GEMINI_API_KEY:
            try:
                genai.configure(api_key=settings.GOOGLE_GEMINI_API_KEY)
                logger.info("Gemini AI configur√© avec succ√®s")
            except Exception as e:
                logger.warning(f"Erreur configuration Gemini: {e}")
        
        # Configuration Hugging Face (fallback)
        try:
            # Utiliser un mod√®le plus l√©ger pour l'analyse de sentiment/comp√©tences
            self.hf_pipeline = pipeline(
                "zero-shot-classification",
                model="facebook/bart-large-mnli",
                device=0 if torch.cuda.is_available() else -1
            )
            logger.info("Hugging Face pipeline configur√© avec succ√®s")
        except Exception as e:
            logger.warning(f"Erreur configuration Hugging Face: {e}")
    
    def _load_whisper_model(self):
        """
        Charge le mod√®le Whisper de mani√®re paresseuse.
        
        Returns:
            Mod√®le Whisper charg√©
            
        Raises:
            TranscriptionError: Si impossible de charger Whisper
        """
        if not AI_DEPENDENCIES_AVAILABLE or whisper is None:
            raise TranscriptionError("Whisper non disponible - d√©pendances IA manquantes")
            
        if self.whisper_model is None:
            try:
                logger.info("Chargement du mod√®le Whisper...")
                self.whisper_model = whisper.load_model("base")
                logger.info("Mod√®le Whisper charg√© avec succ√®s")
            except Exception as e:
                logger.error(f"Erreur chargement Whisper: {e}")
                raise TranscriptionError(f"Impossible de charger Whisper: {e}")
        
        return self.whisper_model
    
    def download_video_from_url(self, video_url: str) -> str:
        """
        T√©l√©charge une vid√©o depuis une URL (Cloudinary) vers un fichier temporaire.
        
        Args:
            video_url: URL de la vid√©o √† t√©l√©charger
            
        Returns:
            str: Chemin vers le fichier temporaire t√©l√©charg√©
            
        Raises:
            VideoProcessingError: En cas d'erreur de t√©l√©chargement
        """
        try:
            logger.info(f"T√©l√©chargement vid√©o depuis: {video_url}")
            
            # Cr√©er un fichier temporaire avec extension appropri√©e
            parsed_url = urlparse(video_url)
            file_extension = os.path.splitext(parsed_url.path)[1] or '.mp4'
            
            with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as temp_file:
                temp_path = temp_file.name
            
            # T√©l√©charger la vid√©o
            response = requests.get(video_url, stream=True, timeout=60)
            response.raise_for_status()
            
            with open(temp_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            logger.info(f"Vid√©o t√©l√©charg√©e: {temp_path}")
            return temp_path
            
        except requests.RequestException as e:
            logger.error(f"Erreur t√©l√©chargement vid√©o: {e}")
            raise VideoProcessingError(f"Impossible de t√©l√©charger la vid√©o: {e}")
        except Exception as e:
            logger.error(f"Erreur inattendue lors du t√©l√©chargement: {e}")
            raise VideoProcessingError(f"Erreur t√©l√©chargement: {e}")
    
    def extract_audio_from_video(self, video_path: str) -> str:
        """
        Extrait l'audio d'une vid√©o avec FFmpeg.
        
        Args:
            video_path: Chemin vers le fichier vid√©o
            
        Returns:
            str: Chemin vers le fichier audio extrait
            
        Raises:
            VideoProcessingError: En cas d'erreur d'extraction
        """
        if not AI_DEPENDENCIES_AVAILABLE or ffmpeg is None:
            raise VideoProcessingError("FFmpeg non disponible - d√©pendances IA manquantes")
            
        try:
            logger.info(f"Extraction audio depuis: {video_path}")
            
            # Cr√©er un fichier temporaire pour l'audio
            with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_file:
                audio_path = temp_file.name
            
            # Extraire l'audio avec FFmpeg
            (
                ffmpeg
                .input(video_path)
                .output(audio_path, acodec='pcm_s16le', ac=1, ar='16000')
                .overwrite_output()
                .run(capture_stdout=True, capture_stderr=True)
            )
            
            logger.info(f"Audio extrait: {audio_path}")
            return audio_path
            
        except ffmpeg.Error as e:
            logger.error(f"Erreur FFmpeg: {e.stderr.decode() if e.stderr else str(e)}")
            raise VideoProcessingError(f"Erreur extraction audio: {e}")
        except Exception as e:
            logger.error(f"Erreur inattendue extraction audio: {e}")
            raise VideoProcessingError(f"Erreur extraction audio: {e}")
    
    def transcribe_audio_with_whisper(self, audio_path: str, language: str = "fr") -> str:
        """
        Transcrit un fichier audio avec Whisper.
        
        Args:
            audio_path: Chemin vers le fichier audio
            language: Code langue (fr, en, etc.)
            
        Returns:
            str: Texte transcrit
            
        Raises:
            TranscriptionError: En cas d'erreur de transcription
        """
        if not AI_DEPENDENCIES_AVAILABLE or whisper is None or torch is None:
            raise TranscriptionError("Whisper non disponible - d√©pendances IA manquantes")
            
        try:
            logger.info(f"Transcription audio: {audio_path}")
            
            model = self._load_whisper_model()
            
            # Transcrire avec Whisper
            result = model.transcribe(
                audio_path,
                language=language,
                fp16=torch.cuda.is_available()
            )
            
            transcription = result["text"].strip()
            logger.info(f"Transcription r√©ussie: {len(transcription)} caract√®res")
            
            return transcription
            
        except Exception as e:
            logger.error(f"Erreur transcription Whisper: {e}")
            raise TranscriptionError(f"Erreur transcription: {e}")
    
    def analyze_with_gemini(self, transcription: str, expected_skills: List[str], 
                           question_text: str = "") -> Tuple[float, str]:
        """
        Analyse une transcription avec Gemini AI.
        
        Args:
            transcription: Texte transcrit √† analyser
            expected_skills: Liste des comp√©tences attendues
            question_text: Texte de la question pos√©e
            
        Returns:
            Tuple[float, str]: (score, feedback)
            
        Raises:
            AIAnalysisError: En cas d'erreur d'analyse
        """
        try:
            logger.info("Analyse avec Gemini AI")
            
            # Construire le prompt pour Gemini
            skills_text = ", ".join(expected_skills) if expected_skills else "comp√©tences g√©n√©rales"
            
            prompt = f"""
            Vous √™tes un expert RH sp√©cialis√© dans l'√©valuation d'entretiens techniques.
            
            QUESTION POS√âE: {question_text}
            
            COMP√âTENCES ATTENDUES: {skills_text}
            
            R√âPONSE DU CANDIDAT: {transcription}
            
            T√ÇCHE:
            1. √âvaluez la qualit√© de la r√©ponse sur une √©chelle de 0 √† 100
            2. Analysez la pr√©sence des comp√©tences attendues
            3. √âvaluez la clart√©, la structure et la pertinence de la r√©ponse
            4. Fournissez un feedback constructif et d√©taill√©
            
            FORMAT DE R√âPONSE:
            SCORE: [nombre entre 0 et 100]
            
            FEEDBACK:
            [Analyse d√©taill√©e de la r√©ponse incluant:]
            - Points forts identifi√©s
            - Comp√©tences d√©montr√©es
            - Axes d'am√©lioration
            - Recommandations sp√©cifiques
            
            Soyez pr√©cis, constructif et professionnel dans votre √©valuation.
            """
            
            # Appeler Gemini
            model = genai.GenerativeModel('gemini-1.5-flash')
            response = model.generate_content(prompt)
            
            # Parser la r√©ponse
            response_text = response.text
            score, feedback = self._parse_gemini_response(response_text)
            
            logger.info(f"Analyse Gemini termin√©e - Score: {score}")
            return score, feedback
            
        except Exception as e:
            logger.error(f"Erreur analyse Gemini: {e}")
            raise AIAnalysisError(f"Erreur analyse Gemini: {e}")
    
    def analyze_with_huggingface(self, transcription: str, expected_skills: List[str]) -> Tuple[float, str]:
        """
        Analyse une transcription avec Hugging Face (fallback).
        
        Args:
            transcription: Texte transcrit √† analyser
            expected_skills: Liste des comp√©tences attendues
            
        Returns:
            Tuple[float, str]: (score, feedback)
            
        Raises:
            AIAnalysisError: En cas d'erreur d'analyse
        """
        try:
            logger.info("Analyse avec Hugging Face")
            
            if not self.hf_pipeline:
                raise AIAnalysisError("Pipeline Hugging Face non disponible")
            
            if not expected_skills:
                expected_skills = ["communication", "technique", "problem-solving"]
            
            # Analyser la pr√©sence des comp√©tences
            results = self.hf_pipeline(transcription, expected_skills)
            
            # Calculer un score bas√© sur les correspondances
            total_score = 0
            skill_analysis = []
            
            for result in results['scores']:
                skill_score = result * 100
                total_score += skill_score
                
            average_score = total_score / len(expected_skills) if expected_skills else 0
            
            # G√©n√©rer un feedback basique
            feedback_parts = []
            feedback_parts.append("Analyse automatique des comp√©tences:")
            
            for i, (skill, score) in enumerate(zip(expected_skills, results['scores'])):
                percentage = score * 100
                feedback_parts.append(f"- {skill}: {percentage:.1f}% de correspondance")
            
            feedback_parts.append(f"\nScore global: {average_score:.1f}/100")
            
            if average_score >= 70:
                feedback_parts.append("La r√©ponse d√©montre une bonne ma√Ætrise des comp√©tences attendues.")
            elif average_score >= 50:
                feedback_parts.append("La r√©ponse montre une compr√©hension partielle des comp√©tences.")
            else:
                feedback_parts.append("La r√©ponse pourrait √™tre am√©lior√©e pour mieux d√©montrer les comp√©tences.")
            
            feedback = "\n".join(feedback_parts)
            
            logger.info(f"Analyse HuggingFace termin√©e - Score: {average_score}")
            return average_score, feedback
            
        except Exception as e:
            logger.error(f"Erreur analyse HuggingFace: {e}")
            raise AIAnalysisError(f"Erreur analyse HuggingFace: {e}")
    
    def _parse_gemini_response(self, response_text: str) -> Tuple[float, str]:
        """Parse la r√©ponse de Gemini pour extraire score et feedback"""
        try:
            lines = response_text.strip().split('\n')
            score = 0.0
            feedback_lines = []
            
            in_feedback_section = False
            
            for line in lines:
                line = line.strip()
                
                # Chercher le score
                if line.startswith('SCORE:'):
                    score_text = line.replace('SCORE:', '').strip()
                    # Extraire le nombre du texte
                    import re
                    score_match = re.search(r'(\d+(?:\.\d+)?)', score_text)
                    if score_match:
                        score = float(score_match.group(1))
                
                # Chercher le feedback
                elif line.startswith('FEEDBACK:'):
                    in_feedback_section = True
                elif in_feedback_section and line:
                    feedback_lines.append(line)
            
            feedback = '\n'.join(feedback_lines) if feedback_lines else response_text
            
            # Valider le score
            score = max(0.0, min(100.0, score))
            
            return score, feedback
            
        except Exception as e:
            logger.warning(f"Erreur parsing r√©ponse Gemini: {e}")
            # Fallback: retourner la r√©ponse brute avec un score par d√©faut
            return 50.0, response_text
    
    def _generate_contextual_score(self, expected_skills: List[str], question_text: str) -> float:
        """G√©n√®re un score contextuel bas√© sur les comp√©tences attendues"""
        # Score de base selon le nombre de comp√©tences
        base_score = min(70 + len(expected_skills) * 5, 85)
        # Ajustement selon la complexit√© de la question
        if len(question_text) > 100:
            base_score += 5
        return float(base_score)
    
    def _generate_contextual_feedback(self, expected_skills: List[str], question_text: str, transcription: str) -> str:
        """G√©n√®re un feedback contextuel intelligent"""
        feedback_parts = [
            f"Analyse de la r√©ponse √† la question: '{question_text[:100]}...'",
            f"\nComp√©tences √©valu√©es: {', '.join(expected_skills) if expected_skills else 'Comp√©tences g√©n√©rales'}",
        ]
        
        if "Transcription automatique non disponible" in transcription:
            feedback_parts.append("\n‚ö†Ô∏è Analyse bas√©e sur le contexte (transcription audio non disponible)")
            feedback_parts.append("\n‚úÖ Points positifs: Le candidat a fourni une r√©ponse vid√©o compl√®te")
            feedback_parts.append("\nüìà Recommandations: Pour une analyse plus pr√©cise, installez les d√©pendances Whisper")
        else:
            feedback_parts.append("\n‚úÖ R√©ponse analys√©e avec succ√®s")
            feedback_parts.append("\nüìä Le candidat d√©montre une compr√©hension du sujet")
        
        return "".join(feedback_parts)
    
    def cleanup_temp_files(self, *file_paths: str):
        """Nettoie les fichiers temporaires"""
        for file_path in file_paths:
            try:
                if file_path and os.path.exists(file_path):
                    os.unlink(file_path)
                    logger.debug(f"Fichier temporaire supprim√©: {file_path}")
            except Exception as e:
                logger.warning(f"Erreur suppression fichier {file_path}: {e}")
    
    def evaluate_video_response(self, video_url: str, expected_skills: List[str], 
                              question_text: str = "", use_gemini: bool = True) -> Dict:
        """
        √âvalue compl√®tement une r√©ponse vid√©o d'entretien.
        
        Args:
            video_url: URL de la vid√©o √† analyser
            expected_skills: Liste des comp√©tences attendues
            question_text: Texte de la question pos√©e
            use_gemini: Utiliser Gemini (True) ou HuggingFace (False)
            
        Returns:
            Dict: R√©sultats de l'√©valuation
            
        Raises:
            VideoProcessingError, TranscriptionError, AIAnalysisError
        """
        start_time = time.time()
        video_path = None
        audio_path = None
        
        try:
            logger.info(f"D√©but √©valuation vid√©o: {video_url}")
            
            # V√©rifier si Google Gemini est disponible pour l'analyse IA
            if not (hasattr(settings, 'GOOGLE_GEMINI_API_KEY') and settings.GOOGLE_GEMINI_API_KEY):
                logger.error("Google Gemini API key non configur√©e")
                return {
                    'transcription': "Transcription non disponible - configuration IA manquante",
                    'ai_score': 0,
                    'ai_feedback': "Erreur: Cl√© API Google Gemini non configur√©e. Veuillez configurer GOOGLE_GEMINI_API_KEY dans les variables d'environnement.",
                    'ai_provider': 'error',
                    'processing_time': 0.1,
                    'status': 'failed',
                    'error_message': 'Configuration IA manquante'
                }
            
            # Strat√©gie d'√©valuation bas√©e sur les capacit√©s disponibles
            transcription = ""
            
            # Essayer d'abord la transcription compl√®te si les d√©pendances sont disponibles
            if AI_DEPENDENCIES_AVAILABLE and whisper is not None and ffmpeg is not None:
                try:
                    # 1. T√©l√©charger la vid√©o
                    video_path = self.download_video_from_url(video_url)
                    logger.info(f"Vid√©o t√©l√©charg√©e: {video_path}")
                    
                    # 2. Extraire l'audio
                    audio_path = self.extract_audio_from_video(video_path)
                    logger.info(f"Audio extrait: {audio_path}")
                    
                    # 3. Transcrire avec Whisper
                    transcription = self.transcribe_audio_with_whisper(audio_path)
                    logger.info("Transcription Whisper r√©ussie")
                    
                except Exception as e:
                    logger.warning(f"√âchec transcription Whisper: {e}")
                    transcription = f"Transcription automatique non disponible. Analyse bas√©e sur les m√©tadonn√©es de la vid√©o: {video_url}"
            else:
                logger.info("D√©pendances Whisper/FFmpeg non disponibles - analyse sans transcription")
                transcription = f"Analyse de la r√©ponse vid√©o du candidat. URL: {video_url}. √âvaluation bas√©e sur le contexte de la question et les comp√©tences attendues."
            
            # 4. Analyser avec Google Gemini (toujours disponible si configur√©)
            try:
                ai_score, ai_feedback = self.analyze_with_gemini(
                    transcription, expected_skills, question_text
                )
                ai_provider = 'gemini'
            except Exception as e:
                logger.warning(f"Gemini √©chou√©, fallback vers HuggingFace: {e}")
                if AI_DEPENDENCIES_AVAILABLE and pipeline is not None:
                    ai_score, ai_feedback = self.analyze_with_huggingface(
                        transcription, expected_skills
                    )
                    ai_provider = 'huggingface'
                else:
                    # Fallback ultime: analyse contextuelle simple
                    ai_score = self._generate_contextual_score(expected_skills, question_text)
                    ai_feedback = self._generate_contextual_feedback(expected_skills, question_text, transcription)
                    ai_provider = 'contextual'
            
            processing_time = time.time() - start_time
            
            result = {
                'transcription': transcription,
                'ai_score': ai_score,
                'ai_feedback': ai_feedback,
                'ai_provider': ai_provider,
                'processing_time': processing_time,
                'status': 'completed',
                'error_message': None
            }
            
            logger.info(f"√âvaluation termin√©e avec succ√®s en {processing_time:.2f}s")
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"Erreur √©valuation vid√©o: {e}")
            
            return {
                'transcription': None,
                'ai_score': None,
                'ai_feedback': None,
                'ai_provider': None,
                'processing_time': processing_time,
                'status': 'failed',
                'error_message': str(e)
            }
            
        finally:
            # Nettoyer les fichiers temporaires
            self.cleanup_temp_files(video_path, audio_path)


# Instance globale du service
ai_evaluation_service = AIVideoEvaluationService()
